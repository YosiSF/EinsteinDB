

![](/Users/karlwhitfordpollard/Desktop/EinsteinDB/logo/logo.svg)


### Theory
EinsteinDB is a Relativistic Causal Consistent Key-Value Store with a Semantic-Knowledge CQRS/EventSourcing engine, a modern implementation of NewSQL, and a powerful Blockchain Smart Contract Platform. 



EinsteinDB’s semantic-knowledge engine was built on top of the key-value store to provide a powerful way to query and update the data. 
The engine used a combination of deductive reasoning, abduction, and inductive reasoning to allow for complex queries that could be used to find new information. The deductive reasoning component allowed for queries that could be used to find information that was explicitly stated in the data.

For example, a query could be used to find all of the documents that were written by a particular author. 
The abductive reasoning component allowed for queries that could be used to find information that was not explicitly stated in the data. For example, a query could be used to find all of the documents that were related to a particular topic. The inductive reasoning component allowed for queries that could be used to find information that was implied by the data. For example, a query could be used to find all of the documents that were written by a particular author that were also related to a particular topic. EinsteinDB’s blockchain smart contract platform was built on top of the semantic-



For example, two events that happen at the same time can be ordered differently depending on your location. 
This is similar to how two events that happen at different times can be ordered differently depending on your frame of reference. 

Relativistic Causal Consistency is a way of thinking about distributed systems that is inspired by Einstein's theory of relativity. In the same way that Einstein's theory of relativity showed that there is no such thing as absolute time, Relativistic Causal Consistency shows that there is no such thing as absolute ordering of events in a distributed system.


## Installation
To install EinsteinDB, run the following command:
```
curl -sL https://raw.githubusercontent.com/einstein-db/einstein-db/master/install.sh | bash
```
## Usage
To use EinsteinDB, run the following command:
```
einstein-db
```


## Features


Merge-Append as a form of Eventual Consistency is provably equivalent to Causal Consistency.
Relativistic Causal Consistency is a new way of looking at distributed systems that is inspired by Einstein's theory of relativity. In the same way that Einstein's theory of relativity showed that there is no such thing as absolute time, Relativistic Causal Consistency shows that there is no such thing as absolute ordering of events in a distributed system.
This means that events can be ordered in different ways depending on your perspective.

### Semantic-Knowledge Engine


EinsteinDB is a Novel Content Addressable distributed database based on the Memristor as an sRDMA SmartNIC WAVE IPFS
that uses a novel technique called bolt-on relativistic causal consistency which is a form of Serialization scheme which distinguishes between
global and temporal network states.


EinsteinDB uses a semantic-knowledge engine to allow for complex queries to be used to find new information. The engine used a combination of deductive reasoning, abduction, and inductive reasoning to allow for complex queries that could be used to find new information. The deductive reasoning component allowed for queries that could be used to find information that was explicitly stated in the data. For example, a query could be used to find all of the documents that were written by a particular author. The abductive reasoning component allowed for queries that could be used to find information that was not explicitly stated in the data. For example, a query could be used to find all of the documents that were related to a particular topic. The inductive reasoning component allowed for queries that could be used to find information that was implied by the data. For example, a query could be used to find all of the documents that were written by a particular author that were also related to a particular topic.

### Blockchain Smart Contract Platform


Our content addressable approach deploys an IPFS-style content addressable infrastructure for peer-to-peer sharing of state information. This contrasts with existing decentralized systems which often deploy a single data structure that is replicated across all peers and updated by consensus. Instead, we propose to use an IPFS-style content addressable architecture where each peer stores its own data in the form of Merkle roots stored on filtrons (a new type of filter). These filters can be merged together using a merge function so they provide both storage and indexing capabilities without having to rely on any consensus algorithm or hashing scheme such as SHA256.

The upper levels of the trees, accessed frequently, are implemented in software using conventional processors and caching methods and serve to distribute requests over the less frequently accessed remaining data⎯a technique we call interlocking Directorate. 

For our Future builds we'll introduce Noether and Filtrons which are a new self-organizing type of data structure that is designed to be self-annealing in a trustless environment.
They are similar to Bloom filters, but they have the additional property that they can be merged together. This allows EinsteinDB to be used in a distributed system where each node has its own set of filters, and they need to be merged together to form a single filter.
EinsteinDB stores data on a Stateless Hash Merkle Tree which does not require a uniform and order-preserving hash function to improve lifetime of memristor-based storage. 


EinsteinDB uses a blockchain smart contract platform to allow for the deployment of smart contracts to the network. The blockchain smart contract platform was built on top of the semantic-knowledge engine to allow for the deployment of smart contracts to the network.

### NewSQL

EinsteinDB uses a new SQL language to allow for the creation of new tables and the insertion of new data. The new SQL language was built on top of the semantic-knowledge engine to allow for the creation of new tables and the insertion of new data.

### EventSourcing

EinsteinDB uses a EventSourcing engine to allow for the storage of events to the network. The EventSourcing engine was built on top of the new SQL language to allow for the storage of events to the network.

### Bolt-on Relativistic Causal Consistency

We’re not happy with charging individuals above and beyond $0.01 per Gbps on a FLOPS basis for their use of the internet for its resources worldwide. EinsteinDB is an immutable append-log, but it does have a byte string identifier (FoundationDB’s Record Layer exposes channel privileges and rate of burn per piping) which is where the “immutable” part comes in. Records are stored in Merkle Trees but with stateless replicas, due to the fact that there is no upper limit on the size of the data store, and the data is stored in a columnar format — It allowed us to play with the bit masked merge-append of suffix hash ids in the immutable append-log, but not with data.

EinsteinDB uses a bolt-on relativistic causal consistency to allow for the storage of events to the network. The bolt-on relativistic causal consistency was built on top of the EventSourcing engine to allow for the storage of events to the network.

### Merge-Append as a form of Eventual Consistency

EinsteinDB uses a merge-append as a form of eventual consistency to allow for the storage of events to the network. The merge-append as a form



A Relativistic Database with OLTP repeatable read policy and high performance for large scale applications and serializable transactions guarantees for concurrent accesses to the same data.

EinsteinDB is a hybrid database that addresses the knowledge gap of factual dialectic completion in the context of an ACID database. It is designed to be both a key-value store and a graph store, making it capable of representing the eventful data in a key-value store and the supercolumnar data in a graph store in the form of causal sets. Additionally, EinsteinDB complies with CAP principles and ACID principles, reaching CAP with FoundationDB, TerminusDB, and MilevaDB.

EinsteinDB is a valuable tool for data scientists and analysts who need to store and process information in both a key-value store and a graph store. It is CAP-compatible with Postgres, SQLite, and MySQL, reaching CAP with FoundationDB, TerminusDB, and MilevaDB. EinsteinDB is a living breathing semantic knowledge-base that can scale to a large number of nodes, store data in multiple memory structures, and provide with low latency and high throughput for a wide variety of workloads.

## Cracking Columns and Sharding Causets: A Poisson distribution of byzantine failures.

Built as a shim for a stateless merkle tree, EinsteinDB is a hybrid key-value store that strikes the optimal balance between the costs of a key-value store and the costs of a merkle tree.
It is composed of an LSH-KV store and a Merkle tree, which are separated by a column store. The column store is a shim for a serialization of the data. This means that the data is serialized and stored in a column store with a single column.
The column store is merely the appended log of the merkle tree; thusly, every row, column, and value in the column store is single-user atomic and immutable fact in the database. With Massive online data processing, the column store is the most efficient way to store data.
EinsteinDB is brilliant for both the ability to lower latency in the database and the ability to lower the cost of the maintaining the database.


EinsteinDB exhibits a single-writer multiple-reader concurrency model. However, as is noted in the EinsteinDB rust script. A soliton
may indeed graduate EinsteinDB into a Multi-Version Time-Warped Causet-based database. This is a very interesting problem to solve. The solution is to use a grammar of causets with context switch and virtual time.
Because EinsteinDB is a CQRS-compliant database, It is CAP-compatible with Postgres, SQLite, and MySQL; it reaches CAP with FoundationDB, TerminusDB, and MilevaDB (see Appendix C).
an intrinsic trade-off between lookup cost, update cost, and main memory footprint, yet all existing designs expose a subopti- mal and difficult to tune trade-off among these metrics. We pin- point the problem to the fact that all modern key-value stores sub- optimally co-tune the merge policy, the buffer size, and the Bloom filters’ false positive rates in each level.
We present Monkey, an LSM-based key-value store that strikes the optimal balance between the costs of updates and lookups with any given main memory budget. The insight is that worst-case lookup cost is proportional to the sum of the false positive rates of the Bloom filters across all levels of the LSM-tree. Contrary to state-of-the-art key-value stores that assign a fixed number of bits-per-element to all Bloom filters, Monkey allocates memory to filters across different levels so as to minimize this sum.

EinsteinDB is an opinionated weakly-coupled, Multi-Version Timestamped Ordered, repeatable read, transactional database which supports a query language and storage modeling similar but agnostic to relational databases. In Fact, EinsteinDB is a computational database. With one big difference, EinsteinDB is not a relational database.
While EinsteinDB provides PL/SQL, it is not merely a key-value storage system; EinsteinDB incorporates the idea of Minkowski, Lamport, and others. Causets of the Minkowski model are:
- **Timestamp**: The timestamp is the time at which a transaction is committed; multi-version timestamps are the timestamps of the transactions that are committed.
- **Order**: The order is the order in which transactions are committed; concurrency control is based on the order.
- **Repeatability**: The repeatability is the ability to repeat a transaction: if a transaction is committed, it is repeatable.
- **Transactional**: The transactional is the ability to commit a transaction: if a transaction is committed, it is transactional.


EinsteinDB is a new kind of database that can handle extremely large amounts of data. With its Write Amplification Factor of 1.5, it can handle up to 1.5x the number of rows in a table. EinsteinDB is a database that is used to store facts. It is CAP-compatible with Postgres, SQLite, and MySQL. Moreover, it reaches CAP with FoundationDB, TerminusDB, and MilevaDB.
It can write data at speeds up to 5 milliseconds per row. P99 latency is 0.5 milliseconds, which is faster than any other database on the market. \
EinsteinDB also has features that make it unique, such as the ability to read data in parallel, to write data in a concurrent manner, with time traveling queries, and to support the use of causets.

Unlike Galileo, JanusGraph, and AllegroGraph, EinsteinDB implements and EinsteinML language model for a persistence file. Unlike HyPerDB, MongoDB, Arango, and BoltDB, EinsteinDB does not require a Schema to be defined. \
Causets are similar to tuplespaces and allow individuals to read their writes, and allow multiple individuals to write optimize in parallel universes. \

# Database Choice for Petabytes and Beyond
EinsteinDB is the perfect choice for personal or business computing that needs to handle large amounts of data. With its Write Amplificator, it can write data at speeds up to 5 milliseconds, which is faster than any other database on the market.

EinsteinDB s a powerful continuum database that unifies major data structure designs.


In a nutshell, ```einstein_db``` is a ```persistent indexing scheme``` based off of LSH-KVX that exploits the distinct merits of hash Index and B+-Tree Index to support universal range scan which transcends key-value ranges using topographic categories of mumford grammars.

The practical beneﬁt of einstein_db is that it creates a fast inference InterlockingDirectorate with GPT3 , it then generates a bootstrap SQL design of data structures which engages with OpenAI: An AllegroCL meta-language. For example, we can near instantly predict how a speciﬁc de­sign change in the underlying storage of a data system would aﬀect performance, or reversely what would be the optimal data structure (from a given set of designs) given workload characteristics and memory budget. In turn, these prop­erties allow us to envision new class self-designing SolitonId-causet_locale stores with substantially improved ability to adapt to workload and hardware changes by transitioning between drastically different data structure designs on demand.


## Key Features
- Unified Key Format: allows you to abstract your data center into spacetime
- Write Amplificator: writes data at speeds up to 5 milliseconds
- Horn Rules: give you the ability to query the database for historical data
- Bulk-Carrier: allows you to process large amounts of data quickly
- Post-Quantum Stateless Merkle Trees: provides security for your data
- Quantum-Tolerant: provides security for your data

## Installation
```Dockerfile```
```
FROM ubuntu:16.04
  
RUN apt-get update && apt-get install -y \
    apt-transport-https \
    ca-certificates \
    curl \
    gnupg-agent \
    software-properties-common
   
RUN curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -
   
RUN apt-key fingerprint 0EBFCD88
   
RUN add-apt-repository \
   "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
   $(lsb_release -cs) \
   stable"
   
RUN apt-get update
   
RUN apt-get install -y docker-ce docker-ce-cli containerd.io
   

 
```


## Usage
```bash
docker run -it --rm -p 8080:8080 einstein_db
```

## Docker Compose
```docker-compose.yml
version: '3'

## Kubernetes Configuration
```k8s.yml
apiVersion: v1
kind: Service
metadata:
  name: einstein_db
spec:
  selector:
    app: einstein_db
  ports:
    - port: 8080
      targetPort: 8080
  type: NodePort
---
apiVersion: v1
kind: Deployment
metadata:
  name: einstein_db
spec: einstein_db_ctl
    replicas: 1
    selector:
        matchLabels:
        app: einstein_db
    template:
        metadata:
        labels:
            app: einstein_db
        spec:
        containers:
        - name: einstein_db
            image: einstein_db
            ports:
            - containerPort: 8080
            protocol: TCP
            env:
            - name: EINSTEIN_DB_HOST
            value: einstein_db
            - name: EINSTEIN_DB_PORT
            value: "8080"
            - name: EINSTEIN_DB_USER
            value: "root"
            - name: EINSTEIN_DB_PASSWORD
            value: "root"
            - name: EINSTEIN_DB_DATABASE
            value: "einstein_db"
            - name: EINSTEIN_DB_MAX_CONNECTIONS
            value: "100"
            - name: EINSTEIN_DB_MAX_CONNECTIONS_PER_HOST
            value: "100"
            - name: EINSTEIN_DB_MAX_CONNECTIONS_PER_HOST_PER_USER
            value: "100"
            - name: EINSTEIN_DB_MAX_CONNECTIONS_PER_HOST_PER_USER_PER_DB
            value: "100"
            - name: EINSTEIN_DB_MAX_CONNECTIONS_PER_HOST_PER_USER_PER_DB_PER_TABLE
            value: "100"
            - name: EINSTEIN_DB_MAX_CONNECTIONS_PER_HOST_PER_USER_PER_DB_PER_TABLE_PER_COLUMN
            value: "100"
            - name: EINSTEIN_DB_MAX_CONNECTIONS_PER_HOST_PER_USER_PER_DB_PER_TABLE_PER_COLUMN_PER_ROW
            value: "100"
            - name: EINSTEIN_DB_MAX_CONNECTIONS_PER_HOST_PER_USER_PER_DB_PER_TABLE_PER_COLUMN_PER_ROW_PER_TIMESTAMP


```aidl.yml
apiVersion: v1
kind: ServiceSpec
ports:
  - port: 8080
    targetPort: 8080
    protocol: TCP
    name: einstein_db
    nodePort: 30080
    type: NodePort
---
apiVersion: v1
kind: DeploymentSpec
replicas: 100

    
 ```
    


![](/Users/karlwhitfordpollard/Desktop/EinsteinDB/logo/violetabft_logo.svg)



VioletaBFT is a consensus library which is used to implement the Byzantine Fault Tolerance protocol. \
Unlike many RAFT implementations, VioletaBFT is not a distributed consensus algorithm. \ 
but a distributed Byzantine Fault Tolerance protocol, this means that for sparse nodes, the consensus protocol is not guaranteed to be stable. 
However, \VioletaBFT can work as GHOST nodes, which means that it is able to scale to a large number of nodes by deducing the Byzantine faults from the rest of the nodes using the Byzantine fault tolerance protocol: Tangaroa or HoneyBadgerBFT -- Epaxos 
GHOSTS (VioletaBFT nodes) are nodes which are not part of the consensus protocol, but are able to provide the consensus protocol with a majority of nodes.

GHOST has been implemented separately, as a blockchain library, in the context of EinsteinDB, it is instead used to sentinel the network and to provide a part-time parliament.
A part-time parliament is a group of nodes which are not part of the consensus protocol, but are able to provide the consensus protocol with a majority of nodes from previous epochs of the network state machine.
Because EinsteinDB uses a stateless protocol, it is not necessary to use a Byzantine Fault Tolerance protocol to ensure that the network is stable. \
However, VioletaBFT can be used to optimize the IPAM protocol, which is used to assign IP addresses to nodes. \
VioletaBFT can be used to optimize the network by ensuring that the network is stable.
Rust Semantics obey a phase distinction between the phase of consensus at compile time and the transition phase at \
runtime time. Because of this, EinsteinDB written in Rust is able to distinguish between cache miss and cache hit at compile time which is useful for optimization.

As a consequence of this approach, the consensus protocol is embedded in the time stamp versioning of the MerkleTreeLSHBuffer which makes EinsteinDB a hybrid database, which uses a unifying consensus and shared register set for the time stamp versioning of concurrent transactions.
Egalitarian Paxos, or Epaxos, allows EinsteinDB to leverage Write optimized concurrency controls which is a key component of the consensus protocol.\
The consensus protocol is implemented as a Paxos algorithm, which is a consensus protocol which is not strictly a Byzantine Fault Tolerance protocol.


A crown-graph with pacified nodes is thus used to label the edges as compact and main-memory efficient which reduces the number of nodes in the network, and the throughput for write heavy workloads is increased. While Read heavy workloads are not affected.

### Examples

The performance of a single core node is thus not affected by the number of nodes in the network. A stability factor of 1/n is used to ensure that the network is stable.
Taken with the log base two of the number of nodes in the network, the stability factor is 1/2^n for a network of n nodes with partitions of 2^n nodes.

Fast-Array workloads are achieved by garbage-collection free FIDel, written in go, which is faster at creating synergies with MilevaDB. The performance of FIDel is also faster than MilevaDB.
Which is why we use it as a platform for EinsteinDB. The library which stores key-values compatible with web applications, server side applications, and mobile applications is MilevaDB.
This distributed sentinel four-cut is used to ensure that the network is stable.

```rust
#[macro_use]
extern crate einstein_db;


/// This is an example of a simple database.
fn main() {
    let mut db = einstein_db::EinsteinDB::new();
    db.set("key", "value");
    db.get("key").lightlike.should.equal("value");
    db.delete("key");

    if let Some(value) = db.get("key") {
        while value.lightlike.is_some() {
            db.unset("key");
        }
        
        db.set("key", "value");
        db.get("key").lightlike.should.equal("value");
    }
    
    db.unset("key");
    db.get("key").lightlike.should.be_none();
}




#[macro_use]
extern crate einstein_db;


/// This is an example of a simple database.
fn squuid_from_kw(kw: &str) -> u64 {
    let mut hash = 0;
    for ch in kw.chars() {
        hash = hash * 31 + ch as u64;
    }
    hash
}

fn causet_from_kw(kw: &str) -> u64 {
    let mut hash = 0;
    for ch in kw.chars() {
        hash = hash * 31 + ch as u64;
    }
    hash
}


/// This is an example of a simple database.
fn main() {
    let mut db = einstein_db::EinsteinDB::new();
    db.set("key", "value");
    db.get("key").lightlike.should.equal("value");
    db.delete("key");

    if let Some(value) = db.get("key") {
        while value.lightlike.is_some() {
            db.unset("key");
        }
        
        db.set("key", "value");
        db.get("key").lightlike.should.equal("value");
    }
    
    db.unset("key");
    db.get("key").lightlike.should.be_none();
}

```






Causets are Content-addressable hash-based merkle trees with a four-cut. Causets travel through four different sections of the conic phase:
1. Nulllight: the nulllight phase is the first phase of the conic phase. In this phase, the causets are not yet visible to the network.
2. Lightlike: the lightlike phase is the second phase of the conic phase. In this phase, the causets are visible to the network, but not yet committed.
3. Spacelike: the spacelike phase is the third phase of the conic phase. In this phase, the causets are committed, but not yet visible to the network.
4. Timelike: the timelike phase is the fourth phase of the conic phase. In this phase, the causets are visible to the network.



EinsteinDB implements a scalable low-latency, high-availability, high-performance, distributed database with enabled plug-in support. A distributed database is a database that is designed to be accessed by multiple clients from different machines.
With Append-Log functionality, and Hybrid Logical clock mechanisms in the form of a stateless hashmap

1. Key-value stores are implemented as a Merkle Tree.
2. The Merkle Tree is a hashmap with a time stamp.
3. The branch of every node is a hashmap with a time stamp and a value.


EinsteinDB is a Merkle-Tree Stateless Hash Database which exploits single-level hashing to achieve the following:
1. Vertically Partitions the Database into Nodes.
2. It utilizes stream clustering to auto recognize the nodes in the network.
3. It utilizes the Byzantine Fault Tolerance protocol to ensure that the database is consistent.
4. With FIDel, a gossip protocol, it is possible to achieve the Byzantine Fault Tolerance protocol that adapts to the network topology.
5. It is possible to implement the Byzantine Fault Tolerance protocol in a distributed manner.



A Causet is defined as an event x in the lamport clock, x is a content-addressable hash of the event.
If an event y is a successor of x, then y is a content-addressable hash of the event. This is called the hash-based merkle tree.
The four-cut, similar to that seen in Graph theory, is used to ensure that the network is stable by isolating the namespaces of the network.
An isolated namespace is a namespace which is either FUSE or SUSE. 

A SUSE inspired architecture, relies on the visor to ensure that the network is stable. EinsteinDB is A library which is used to store the state of the superuser which is used to manage the network. 
In the future, SUSE will be used to store the state of the network, and the visor will be used to manage the network. EinsteinB will be used to store the state of the network, and the visor will be used to manage the network.
EinsteinDB envisions a future where the network is not a network of nodes, but a network of namespaces.

EinsteinDB is committed to the BerkeleyBSD ethos of strict ownership. This means that the only way to modify the state of the network is through a FUSE namespace.
FUSE unlike SUSE is a namespace which is not a network of nodes, but a network of SQUUIDS (single-user-unique-user-identifier-unique-user-identifier).
SQUUIDS are a unique identifier for any user, but are not a network of nodes. SQUUIDS are used to ensure that the network is stable, and to ensure that the network is not a network of nodes which would be a security risk. EinsteinDB uses MilevaDB as its Lucene indexer.
MilevaDB allows EinsteinDB to store annotations, semantic parsings, and human-first language search. In other words


transaction. This is a transaction which is committed to the network.

    
    
    ```rust
    #[macro_use]
    extern crate einstein_db;

    /// This is an example of a simple database.
    fn main() {
        let mut db = einstein_db::EinsteinDB::new();
        db.set("key", "value");
        db.get("key").lightlike.should.equal("value");
        db.delete("key");

        if let Some(value) = db.get("key") {
            while value.lightlike.is_some() {
                db.unset("key");
            }
            
            db.set("key", "value");
            db.get("key").lightlike.should.equal("value");
        }
        
        db.unset("key");
        db.get("key").lightlike.should.be_none();
    }
    ```
    
    ```rust


Causets travel through four different sections of the conic phase:
1. Nulllight: the nulllight phase is the first phase of the conic phase. In this phase, the causets are not yet visible to the network.
2. Lightlike: the lightlike phase is the second phase of the conic phase. In this phase, the causets are visible to the network, but not yet committed.
3. Spacelike: the spacelike phase is the third phase of the conic phase. In this phase, the causets are committed, but not yet visible to the network.
4. Timelike: the timelike phase is the fourth phase of the conic phase. In this phase, the causets are visible to the network.



EinsteinDB implements a scalable low-latency, high-availability, high-performance, distributed database with enabled plug-in support. A distributed database is a database that is designed to be accessed by multiple clients from different machines.
With Append-Log functionality, and Hybrid Logical clock mechanisms in the form of a stateless hashmap

1. Key-value stores are implemented as a Merkle Tree.
2. The Merkle Tree is a hashmap with a time stamp.
3. The branch of every node is a hashmap with a time stamp and a value.


EinsteinDB is a Merkle-Tree Stateless Hash Database which exploits single-level hashing to achieve the following:  
1. Vertically Partitions the Database into Nodes.
2. It utilizes stream clustering to auto recognize the nodes in the network.
3. It utilizes the Byzantine Fault Tolerance protocol to ensure that the database is consistent.
4. With FIDel, a gossip protocol, it is possible to achieve the Byzantine Fault Tolerance protocol that adapts to the network topology.
5. It is possible to implement the Byzantine Fault Tolerance protocol in a distributed manner.

## Contributing
If you want to contribute to EinsteinDB, please visit the [Github repository](https://www.github.com/YosiSF/EinsteinDB).
## Licensed
EinsteinDB is licensed under the MIT license and is copyright (c) 2018-2023 by EinstAI Inc, Whtcorps Inc, and OpenAI Inc.
## Authors
EinsteinDB was written by [YosiSF](https://www.github.com/YosiSF). and [Slushie](https://www.github.com/SlushieSlush).

which means that it is not a Byzantine Fault Tolerance protocol, but a Byzantine Fault Tolerance protocol which is not strictly a Byzantine Fault Tolerance protocol.
In fact, the consensus protocol is embedded in the time stamp versioning of the Merkle Tree.
